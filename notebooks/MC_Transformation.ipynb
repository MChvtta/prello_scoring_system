{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0j9hJqlFaEc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ‚öôÔ∏è **CLEANED DATA IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.io as pio\n",
    "#pio.renderers.default = 'iframe'\n",
    "\n",
    "DATA_PATH = '../data/cleaned'\n",
    "\n",
    "POI_FILENAME = 'poi_df_cleaned.csv'\n",
    "SITE_FILENAME = 'site_df_cleaned.csv'\n",
    "SALARY_FILENAME = 'salary_df_cleaned.csv'\n",
    "GEOREF_FILENAME = 'georef_df_cleaned.csv'\n",
    "STOCK_FILENAME = 'stock_df_cleaned.csv'\n",
    "SALES_FILENAME = 'sales_df_cleaned.csv'\n",
    "POPULATION_FILENAME = 'population_df_cleaned.csv'\n",
    "POVERTY_FILENAME = 'poverty_df_cleaned.csv'\n",
    "REAL_ESTATE_FILENAME = 'real_estate_df_cleaned.csv'\n",
    "\n",
    "poi_df = pd.read_csv(os.path.join(DATA_PATH, POI_FILENAME))\n",
    "site_df = pd.read_csv(os.path.join(DATA_PATH, SITE_FILENAME))\n",
    "salary_df = pd.read_csv(os.path.join(DATA_PATH, SALARY_FILENAME))\n",
    "georef_df = pd.read_csv(os.path.join(DATA_PATH, GEOREF_FILENAME))\n",
    "stock_df = pd.read_csv(os.path.join(DATA_PATH, STOCK_FILENAME))\n",
    "sales_df = pd.read_csv(os.path.join(DATA_PATH, SALES_FILENAME))\n",
    "population_df = pd.read_csv(os.path.join(DATA_PATH, POPULATION_FILENAME))\n",
    "poverty_df = pd.read_csv(os.path.join(DATA_PATH, POVERTY_FILENAME))\n",
    "real_estate_df = pd.read_csv(os.path.join(DATA_PATH, REAL_ESTATE_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26216 entries, 0 to 26215\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   poi                26216 non-null  object \n",
      " 1   latitude           26216 non-null  float64\n",
      " 2   longitude          26216 non-null  float64\n",
      " 3   municipality_code  26216 non-null  object \n",
      " 4   importance         26216 non-null  float64\n",
      " 5   name_reprocessed   26216 non-null  object \n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 1.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31034 entries, 0 to 31033\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   poi                      31034 non-null  object \n",
      " 1   name                     31034 non-null  object \n",
      " 2   latitude                 31034 non-null  float64\n",
      " 3   longitude                31034 non-null  float64\n",
      " 4   municipality_code        31034 non-null  object \n",
      " 5   importance               31034 non-null  float64\n",
      " 6   name_reprocessed         31034 non-null  object \n",
      " 7   data_inside_parenthesis  21135 non-null  object \n",
      " 8   Category                 31034 non-null  object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 2.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26675 entries, 0 to 26674\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   municipality_code  26675 non-null  object \n",
      " 1   avg_net_salary     26675 non-null  float64\n",
      " 2   year               26675 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 625.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34997 entries, 0 to 34996\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   municipality_code     34997 non-null  object \n",
      " 1   city_name             34997 non-null  object \n",
      " 2   city_name_normalized  34997 non-null  object \n",
      " 3   municipality_type     34997 non-null  object \n",
      " 4   latitude              34997 non-null  float64\n",
      " 5   longitude             34997 non-null  float64\n",
      " 6   department_code       34997 non-null  object \n",
      " 7   epci_code             34945 non-null  float64\n",
      " 8   department_name       34997 non-null  object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 2.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 279584 entries, 0 to 279583\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   municipality_code     279584 non-null  object \n",
      " 1   year                  279584 non-null  int64  \n",
      " 2   nb_principal_home     279584 non-null  int64  \n",
      " 3   nb_second_home        279584 non-null  int64  \n",
      " 4   nb_vacants_housing    279584 non-null  int64  \n",
      " 5   nb_tot_housing        279584 non-null  int64  \n",
      " 6   secondary_home_rate   279584 non-null  float64\n",
      " 7   principal_home_rate   279584 non-null  float64\n",
      " 8   vacants_housing_rate  279584 non-null  float64\n",
      "dtypes: float64(3), int64(5), object(1)\n",
      "memory usage: 19.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3448398 entries, 0 to 3448397\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   sales_date                 object \n",
      " 1   sales_amount               float64\n",
      " 2   street_number              float64\n",
      " 3   street_code                object \n",
      " 4   street_name                object \n",
      " 5   nom_commune                object \n",
      " 6   municipality_code          object \n",
      " 7   premise_type               object \n",
      " 8   surface                    float64\n",
      " 9   number_of_principal_rooms  int64  \n",
      " 10  sales_price_m2             float64\n",
      " 11  latitude                   float64\n",
      " 12  longitude                  float64\n",
      "dtypes: float64(6), int64(1), object(6)\n",
      "memory usage: 342.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 689495 entries, 0 to 689494\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   municipality_code  689495 non-null  object \n",
      " 1   year               689495 non-null  int64  \n",
      " 2   population         689495 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 15.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 689495 entries, 0 to 689494\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   municipality_code  689495 non-null  object \n",
      " 1   year               689495 non-null  int64  \n",
      " 2   population         689495 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 15.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34441 entries, 0 to 34440\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   municipality_code       34441 non-null  object \n",
      " 1   intensite_tension_immo  34441 non-null  int64  \n",
      " 2   rental_max_apartment    34441 non-null  float64\n",
      " 3   rental_min_apartment    34441 non-null  float64\n",
      " 4   rental_med_all          34441 non-null  float64\n",
      " 5   rental_max_all          34441 non-null  float64\n",
      " 6   rental_min_all          34441 non-null  float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# DF CLEANED CHECK\n",
    "poi_df.info()\n",
    "site_df.info()\n",
    "salary_df.info()\n",
    "georef_df.info() \n",
    "stock_df.info() \n",
    "sales_df.info()\n",
    "population_df.info() \n",
    "poverty_df.info()\n",
    "real_estate_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ-ON4l9sVwu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ-ON4l9sVwu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DF_SALES CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FclUrSzCGdSX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3448398, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SALES_DF: Suppression des doublons > nous passons de 4,3M de lignes √† 3,821M\n",
    "sales_df = sales_df.drop_duplicates()\n",
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SALES_DF: Check si les doublons on √©t√© enlev√©s : OK\n",
    "sales_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALES_DF: Suppression des prix au m2 sup√©rieur √† 30K‚Ç¨ et inf√©rieur √† 1K‚Ç¨ > nous passons √† 3,3399M de lignes\n",
    "sales_df = sales_df[(sales_df['sales_price_m2'] <= 30000) & (sales_df['sales_price_m2'] >= 1000)]\n",
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALES_DF:\n",
    "s2 = (sales_df['sales_amount']\n",
    "             .value_counts()\n",
    "             .loc[sales_df['sales_amount'].value_counts() > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALES_DF:\n",
    "sales_df = sales_df[sales_df['sales_amount'] > 1] # on enl√®ve les 166 fois ou sales_amount = 1‚Ç¨\n",
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3448398 entries, 0 to 3448397\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Dtype         \n",
      "---  ------                     -----         \n",
      " 0   sales_date                 datetime64[ns]\n",
      " 1   sales_amount               float64       \n",
      " 2   street_number              float64       \n",
      " 3   street_code                object        \n",
      " 4   street_name                object        \n",
      " 5   nom_commune                object        \n",
      " 6   municipality_code          object        \n",
      " 7   premise_type               object        \n",
      " 8   surface                    float64       \n",
      " 9   number_of_principal_rooms  int64         \n",
      " 10  sales_price_m2             float64       \n",
      " 11  latitude                   float64       \n",
      " 12  longitude                  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(5)\n",
      "memory usage: 342.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# SALES_DF: changement du type sales_date en datetime\n",
    "sales_df['sales_date'] = pd.to_datetime(sales_df['sales_date'])\n",
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DF_SALARY CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_SALARY: ROUND avg_net_salary\n",
    "salary_df['avg_net_salary'] = salary_df['avg_net_salary'].round()\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DF_REAL_ESTATE CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_REAL_ESTATE: suppression des nulls\n",
    "real_estate_df = real_estate_df.dropna(axis=1)\n",
    "real_estate_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DF_SITE CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITE_DF: tri avec les donn√©es entre parenth√®ses de la colonne \"name\" inclues\n",
    "\n",
    "import re\n",
    "\n",
    "site_df['data_inside_parenthesis'] = site_df['name'].apply(lambda x: re.search(r'\\((.*?)\\)', x).group(1) if re.search(r'\\((.*?)\\)', x) else '')\n",
    "site_df\n",
    "\n",
    "#suppression de la colonne \"name\" dans un second temps\n",
    "\n",
    "site_df.drop(columns=[\"name\"])\n",
    "\n",
    "#check pour savoir les informations pr√©sentes dans la colonne \"poi\", et si elles correspondent aux valeurs pr√©sentes dans la colonne \"type\"\n",
    "print (site_df[\"poi\"].value_counts())\n",
    "print (site_df[\"data_inside_parenthesis\"].value_counts().head(50))\n",
    "\n",
    "#faire un mapping des colonnes poi, qui sont en fait plus pertinentes que celles de la colonne \"type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITE_DF: cr√©ation d'un dictionnaire int√©grant toutes les diff√©rentes valeurs inclues dans la colonne \"poi\"\n",
    "s = site_df[\"poi\"].value_counts()[site_df[\"poi\"]]\n",
    "{k: \"toto\" for k in s.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITE_DF: cr√©ation d'un dictionnaire avec les cat√©gories associ√©es aux valeurs de la colonne POI\n",
    "\n",
    "category_dict = {'1': 'Patrimoine',\n",
    " '2': 'Patrimoine',\n",
    " 'zoo': 'Entertainment',\n",
    " 'dune': 'Nature',\n",
    " 'park': 'Nature',\n",
    " 'rock': 'Nature',\n",
    " 'sand': 'Nature',\n",
    " 'beach': 'Nature',\n",
    " 'cliff': 'Nature',\n",
    " 'islet': 'Nature',\n",
    " 'ridge': 'Nature',\n",
    " 'water': 'Nature',\n",
    " 'wreck': 'Patrimoine',\n",
    " 'casino': 'Entertainment',\n",
    " 'castle': 'Patrimoine',\n",
    " 'cinema': 'Culture',\n",
    " 'forest': 'Nature',\n",
    " 'geyser': 'Nature',\n",
    " 'marina': 'Nature',\n",
    " 'meadow': 'Nature',\n",
    " 'museum': 'Culture',\n",
    " 'valley': 'Nature',\n",
    " 'theatre': 'Culture',\n",
    " 'volcano': 'Nature',\n",
    " 'wetland': 'Nature',\n",
    " 'heritage': 'Patrimoine',\n",
    " 'monument': 'Patrimoine',\n",
    " 'vineyard': 'Nature',\n",
    " 'viewpoint': 'Nature',\n",
    " 'waterfall': 'Nature',\n",
    " 'allotments': 'Patrimoine',\n",
    " 'attraction': 'Entertainment',\n",
    " 'theme_park': 'Entertainment',\n",
    " 'water_park': 'Entertainment',\n",
    " 'golf_course': 'Entertainment',\n",
    " 'cave_entrance': 'Culture',\n",
    " 'national_park': 'Nature',\n",
    " 'protected_area': 'Nature'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITE_DF: cr√©ation de la colonne \"cat√©gorie\"\n",
    "site_df[\"Category\"] = site_df[\"poi\"].map(category_dict)\n",
    "site_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df.info()\n",
    "site_df.info()\n",
    "salary_df.info()\n",
    "georef_df.info() \n",
    "stock_df.info() \n",
    "sales_df.info()\n",
    "population_df.info() \n",
    "poverty_df.info()\n",
    "real_estate_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_df.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "georef_df.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0j9hJqlFaEc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# üß™ **DATA TRANSFORMATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S"
   },
   "source": [
    "### KPIS AGGREGATION BY DEPARTMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 1. POPULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Salaire moyen par d√©partement\n",
    "# Joindre les informations de g√©olocalisation pour obtenir les d√©partements\n",
    "salary_dep_df = salary_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer le salaire moyen par d√©partement\n",
    "avg_salary_per_department = salary_dep_df.groupby(['department_code', 'department_name'])['avg_net_salary'].mean().reset_index().round()\n",
    "avg_salary_per_department.rename(columns={'avg_net_salary': 'avg_salary'}, inplace=True)\n",
    "avg_salary_per_department.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 √âvolution de la population par d√©partement\n",
    "# Joindre les informations de g√©olocalisation pour obtenir les d√©partements\n",
    "population_dep_df = population_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer l'√©volution de la population par d√©partement (diff√©rence entre les ann√©es)\n",
    "pop_evolution = population_dep_df.groupby(['department_code', 'department_name', 'year'])['population'].sum().unstack().reset_index()\n",
    "pop_evolution['evolution'] = (pop_evolution[pop_evolution.columns[-1]] - pop_evolution[pop_evolution.columns[-2]]) / pop_evolution[pop_evolution.columns[-2]] * 100\n",
    "pop_evolution = pop_evolution[['department_code', 'department_name', 'evolution']]\n",
    "\n",
    "pop_evolution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Taux de pauvret√© par d√©partement\n",
    "# Joindre les donn√©es de population\n",
    "poverty_df = poverty_df.merge(population_df[['municipality_code', 'population']], on='municipality_code', suffixes=('_poverty', '_population'))\n",
    "\n",
    "# Merge avec georef pour avoir le department_name\n",
    "poverty_df = poverty_df.merge(georef_df[['municipality_code', 'department_name']], on='municipality_code', how='left')\n",
    "\n",
    "# Groupe par department_name pour calculer le taux de pauvret√© par d√©partement\n",
    "poverty_by_department = poverty_df.groupby('department_name').agg({\n",
    "    'population_poverty': 'sum',\n",
    "    'population_population': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculer le poverty_rate pour chaque d√©partement\n",
    "poverty_by_department['poverty_rate'] = (poverty_by_department['population_poverty'] / poverty_by_department['population']) * 100\n",
    "\n",
    "# Afficher le r√©sultat\n",
    "poverty_by_department.head()\n",
    "\n",
    "# calcul = poverty_rate = poverty_population / total_population * 100\n",
    "# il faut ensuite le DF qui a poverty_rate √† georef pour r√©cup√©rer le department_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2. TOURISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Nombre de sites touristiques par d√©partement\n",
    "# Joindre les informations de g√©olocalisation pour obtenir les d√©partements\n",
    "site_dep_df = site_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer le nombre de sites touristiques par d√©partement\n",
    "num_sites_per_department = site_dep_df.groupby(['department_code', 'department_name'])['poi'].count().reset_index()\n",
    "num_sites_per_department.rename(columns={'poi': 'nb_sites'}, inplace=True)\n",
    "num_sites_per_department.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Importance moyenne des sites par d√©partement\n",
    "# Calculer l'importance moyenne des sites touristiques par d√©partement\n",
    "avg_site_importance_per_department = site_dep_df.groupby(['department_code', 'department_name'])['importance'].mean().reset_index()\n",
    "avg_site_importance_per_department.rename(columns={'importance': 'avg_site_importance'}, inplace=True)\n",
    "avg_site_importance_per_department.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Stock de logement par d√©partement\n",
    "# Joindre les informations de g√©olocalisation pour obtenir les d√©partements\n",
    "stock_dep_df = stock_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer le stock de logement par d√©partement (nombre total de logements)\n",
    "total_stock_per_department = stock_dep_df.groupby(['department_code', 'department_name'])['nb_tot_housing'].sum().reset_index()\n",
    "total_stock_per_department.rename(columns={'nb_tot_housing': 'total_stock'}, inplace=True)\n",
    "total_stock_per_department.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S"
   },
   "source": [
    "##### 3. REAL ESTATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Rentabilit√© locative au m¬≤ par d√©partement\n",
    "# Joindre les informations de g√©olocalisation pour obtenir les d√©partements\n",
    "real_estate_dep_df = real_estate_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer la rentabilit√© locative moyenne au m¬≤ par d√©partement\n",
    "real_estate_dep_df['avg_rental_yield'] = (real_estate_dep_df['rental_max_all'] + real_estate_dep_df['rental_min_all']) / 2\n",
    "rental_yield_per_department = real_estate_dep_df.groupby(['department_code', 'department_name'])['avg_rental_yield'].mean().reset_index()\n",
    "rental_yield_per_department.rename(columns={'avg_rental_yield': 'avg_rental_yield'}, inplace=True)\n",
    "rental_yield_per_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Tension immobili√®re par d√©partement\n",
    "# Calculer la tension immobili√®re par d√©partement\n",
    "housing_tension_per_department = real_estate_dep_df.groupby(['department_code', 'department_name'])['intensite_tension_immo'].mean().reset_index()\n",
    "housing_tension_per_department.rename(columns={'intensite_tension_immo': 'avg_housing_tension'}, inplace=True)\n",
    "housing_tension_per_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Part de maisons secondaires par d√©partement\n",
    "# Calculer la part de maisons secondaires par d√©partement\n",
    "secondary_home_rate_per_department = stock_dep_df.groupby(['department_code', 'department_name'])['secondary_home_rate'].mean().reset_index()\n",
    "secondary_home_rate_per_department.rename(columns={'secondary_home_rate': 'avg_secondary_home_rate'}, inplace=True)\n",
    "secondary_home_rate_per_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 √âvolution du prix au m¬≤ par d√©partement\n",
    "# Joindre les informations de g√©olocalisation pour obtenir les d√©partements\n",
    "sales_dep_df = sales_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer l'√©volution du prix au m¬≤ par d√©partement\n",
    "price_evolution = sales_dep_df.groupby(['department_code', 'department_name', 'sales_date'])['sales_price_m2'].mean().unstack().reset_index()\n",
    "price_evolution['price_evolution'] = (price_evolution[price_evolution.columns[-1]] - price_evolution[price_evolution.columns[-2]]) / price_evolution[price_evolution.columns[-2]] * 100\n",
    "price_evolution = price_evolution[['department_code', 'department_name', 'price_evolution']]\n",
    "price_evolution.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le prix moyen au m¬≤ des ventes immobili√®res par d√©partement\n",
    "avg_price_per_m2_per_department = sales_dep_df.groupby(['department_code', 'department_name'])['sales_price_m2'].mean().reset_index()\n",
    "avg_price_per_m2_per_department.rename(columns={'sales_price_m2': 'avg_sales_price_m2'}, inplace=True)\n",
    "avg_price_per_m2_per_department.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population\n",
    "1.1 Salaire moyen par d√©partement\n",
    "1.2 √âvolution de la population par d√©partement\n",
    "1.3 Taux de pauvret√© par d√©partement\n",
    "\n",
    "Tourisme\n",
    "2.1 Nombre de sites touristiques par d√©partement\n",
    "2.2 Importance moyenne des sites par d√©partement\n",
    "2.3 Stock de logement par d√©partement\n",
    "\n",
    "Immobilier\n",
    "3.1 Rentabilit√© locative au m¬≤ par d√©partement\n",
    "3.2 Tension immobili√®re par d√©partement\n",
    "3.3 Part de maisons secondaires par d√©partement\n",
    "3.4 √âvolution du prix au m¬≤ par d√©partement\n",
    "3.5 Prix moyen au m¬≤ des ventes immobili√®res par d√©partement\n",
    "creer moi un syst√®me de scoring (avec pond√©ration) pour avoir :\n",
    "\n",
    "un score Population\n",
    "un score Tourisme\n",
    "un score Immobilier\n",
    "puis un Score Global gr√¢ce aux 3 pr√©c√©dents scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que vous avez d√©j√† calcul√© les donn√©es n√©cessaires pour les scores Population, Tourisme et Immobilier\n",
    "\n",
    "# 1. D√©finition des poids pour chaque sous-score dans chaque cat√©gorie\n",
    "weights_population = {\n",
    "    'average_salary': 0.4,\n",
    "    'population_growth': 0.3,\n",
    "    'poverty_rate': 0.3\n",
    "}\n",
    "\n",
    "weights_tourism = {\n",
    "    'num_tourism_sites': 0.4,\n",
    "    'average_importance': 0.3,\n",
    "    'stock_housing': 0.3\n",
    "}\n",
    "\n",
    "weights_real_estate = {\n",
    "    'rental_yield_per_m2': 0.2,\n",
    "    'real_estate_tension': 0.2,\n",
    "    'secondary_home_rate': 0.1,\n",
    "    'price_growth': 0.2,\n",
    "    'average_price_per_m2': 0.3\n",
    "}\n",
    "\n",
    "# 2. Calcul des scores pour chaque cat√©gorie\n",
    "\n",
    "# POPULATION\n",
    "# Supposons que vous avez d√©j√† les dataframes suivants : average_salary_by_department, population_evolution_by_department, average_poverty_rate_by_department\n",
    "\n",
    "population_scores = (\n",
    "    avg_salary_per_department['avg_salary'] * weights_population['average_salary'] +\n",
    "    pop_evolution['evolution'] * weights_population['population_growth'] +\n",
    "    (100 - average_poverty_rate_by_department['poverty_rate']) * weights_population['poverty_rate']\n",
    ")\n",
    "\n",
    "# TOURISM\n",
    "# Supposons que vous avez d√©j√† les dataframes suivants : tourism_sites_by_department, average_importance_by_department, stock_housing_by_department\n",
    "\n",
    "tourism_scores = (\n",
    "    tourism_sites_by_department['num_tourism_sites'] * weights_tourism['num_tourism_sites'] +\n",
    "    average_importance_by_department['importance'] * weights_tourism['average_importance'] +\n",
    "    stock_housing_by_department['stock_housing'] * weights_tourism['stock_housing']\n",
    ")\n",
    "\n",
    "# REAL ESTATE\n",
    "# Supposons que vous avez d√©j√† les dataframes suivants : rental_yield_per_m2_by_department, real_estate_tension_by_department, second_home_rate_by_department, price_growth_by_department, average_price_per_m2_by_department\n",
    "\n",
    "real_estate_scores = (\n",
    "    rental_yield_per_m2_by_department['rental_yield_per_m2'] * weights_real_estate['rental_yield_per_m2'] +\n",
    "    (100 - real_estate_tension_by_department['intensite_tension_immo']) * weights_real_estate['real_estate_tension'] +\n",
    "    (100 - second_home_rate_by_department['secondary_home_rate']) * weights_real_estate['secondary_home_rate'] +\n",
    "    price_growth_by_department['price_growth'] * weights_real_estate['price_growth'] +\n",
    "    average_price_per_m2_by_department['average_price_per_m2'] * weights_real_estate['average_price_per_m2']\n",
    ")\n",
    "\n",
    "# 3. Calcul du score global\n",
    "# Supposons que les scores sont d√©j√† calcul√©s pour chaque cat√©gorie\n",
    "\n",
    "global_score = (\n",
    "    population_scores +\n",
    "    tourism_scores +\n",
    "    real_estate_scores\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser les r√©sultats\n",
    "print(\"Scores Population :\\n\", population_scores.head())\n",
    "print(\"\\nScores Tourisme :\\n\", tourism_scores.head())\n",
    "print(\"\\nScores Immobilier :\\n\", real_estate_scores.head())\n",
    "print(\"\\nScore Global :\\n\", global_score.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPULATION SCORE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Supposons que vous avez d√©j√† calcul√© les sous-scores pour la cat√©gorie Population : average_salary_by_department, population_evolution_by_department, average_poverty_rate_by_department\n",
    "\n",
    "# Initialisation du MinMaxScaler\n",
    "scaler_population = MinMaxScaler()\n",
    "\n",
    "# Normalisation des donn√©es\n",
    "population_scores_scaled = scaler_population.fit_transform(\n",
    "    population_scores[['avg_net_salary', 'population_growth', 'poverty_rate']]\n",
    ")\n",
    "\n",
    "# Calcul des scores normalis√©s\n",
    "population_scores_normalized = (\n",
    "    population_scores_scaled[:, 0] * weights_population['average_salary'] +\n",
    "    population_scores_scaled[:, 1] * weights_population['population_growth'] +\n",
    "    population_scores_scaled[:, 2] * weights_population['poverty_rate']\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser les r√©sultats des scores normalis√©s\n",
    "print(\"Scores Population normalis√©s :\\n\", population_scores_normalized.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOURISM SCORE\n",
    "# Supposons que vous avez d√©j√† calcul√© les sous-scores pour la cat√©gorie Tourisme : tourism_sites_by_department, average_importance_by_department, stock_housing_by_department\n",
    "\n",
    "# Initialisation du MinMaxScaler\n",
    "scaler_tourism = MinMaxScaler()\n",
    "\n",
    "# Normalisation des donn√©es\n",
    "tourism_scores_scaled = scaler_tourism.fit_transform(\n",
    "    tourism_scores[['num_tourism_sites', 'average_importance', 'stock_housing']]\n",
    ")\n",
    "\n",
    "# Calcul des scores normalis√©s\n",
    "tourism_scores_normalized = (\n",
    "    tourism_scores_scaled[:, 0] * weights_tourism['num_tourism_sites'] +\n",
    "    tourism_scores_scaled[:, 1] * weights_tourism['average_importance'] +\n",
    "    tourism_scores_scaled[:, 2] * weights_tourism['stock_housing']\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser les r√©sultats des scores normalis√©s\n",
    "print(\"Scores Tourisme normalis√©s :\\n\", tourism_scores_normalized.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 REAL ESTATE SCORE\n",
    "# Supposons que vous avez d√©j√† calcul√© les sous-scores pour la cat√©gorie Immobilier : rental_yield_per_m2_by_department, real_estate_tension_by_department, second_home_rate_by_department, price_growth_by_department, average_price_per_m2_by_department\n",
    "\n",
    "# Initialisation du MinMaxScaler\n",
    "scaler_real_estate = MinMaxScaler()\n",
    "\n",
    "# Normalisation des donn√©es\n",
    "real_estate_scores_scaled = scaler_real_estate.fit_transform(\n",
    "    real_estate_scores[['rental_yield_per_m2', 'real_estate_tension', 'secondary_home_rate', 'price_growth', 'average_price_per_m2']]\n",
    ")\n",
    "\n",
    "# Calcul des scores normalis√©s\n",
    "real_estate_scores_normalized = (\n",
    "    real_estate_scores_scaled[:, 0] * weights_real_estate['rental_yield_per_m2'] +\n",
    "    real_estate_scores_scaled[:, 1] * weights_real_estate['real_estate_tension'] +\n",
    "    real_estate_scores_scaled[:, 2] * weights_real_estate['secondary_home_rate'] +\n",
    "    real_estate_scores_scaled[:, 3] * weights_real_estate['price_growth'] +\n",
    "    real_estate_scores_scaled[:, 4] * weights_real_estate['average_price_per_m2']\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser les r√©sultats des scores normalis√©s\n",
    "print(\"Scores Immobilier normalis√©s :\\n\", real_estate_scores_normalized.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 GLOBAL SCORE\n",
    "# Supposons que vous avez d√©j√† les scores normalis√©s pour chaque cat√©gorie\n",
    "# population_scores_normalized, tourism_scores_normalized, real_estate_scores_normalized\n",
    "\n",
    "# D√©finition des poids pour chaque cat√©gorie\n",
    "weights = {\n",
    "    'population': 0.4,\n",
    "    'tourism': 0.3,\n",
    "    'real_estate': 0.3\n",
    "}\n",
    "\n",
    "# Calcul du score global pond√©r√©\n",
    "global_score = (\n",
    "    population_scores_normalized * weights['population'] +\n",
    "    tourism_scores_normalized * weights['tourism'] +\n",
    "    real_estate_scores_normalized * weights['real_estate']\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser le score global\n",
    "print(\"Score Global :\\n\", global_score.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# üöÄ ENRICHED EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MtiYSUHHSCws",
    "qzPmsWEUq5zk",
    "Qhf-qyfBrBrU",
    "WUbRvCbWrC-g",
    "IaW8clyJrE7k",
    "gHemM-SqrGyN",
    "wDh1nf-1rIgb",
    "DEROdiJirK6M",
    "-pWIMamvrMgo",
    "i0j9hJqlFaEc",
    "FZ-ON4l9sVwu",
    "XYnKDVU0sb0S",
    "sNX4qmi1Gdyx"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
