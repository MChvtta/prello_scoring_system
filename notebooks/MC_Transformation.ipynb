{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0j9hJqlFaEc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ⚙️ **CLEANED DATA IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.io as pio\n",
    "#pio.renderers.default = 'iframe'\n",
    "\n",
    "DATA_PATH = '../data/cleaned'\n",
    "\n",
    "POI_FILENAME = 'poi_df_cleaned.csv'\n",
    "SITE_FILENAME = 'site_df_cleaned.csv'\n",
    "SALARY_FILENAME = 'salary_df_cleaned.csv'\n",
    "GEOREF_FILENAME = 'georef_df_cleaned.csv'\n",
    "STOCK_FILENAME = 'stock_df_cleaned.csv'\n",
    "SALES_FILENAME = 'sales_df_cleaned.csv'\n",
    "POPULATION_FILENAME = 'population_df_cleaned.csv'\n",
    "POVERTY_FILENAME = 'poverty_df_cleaned.csv'\n",
    "REAL_ESTATE_FILENAME = 'real_estate_df_cleaned.csv'\n",
    "\n",
    "poi_df = pd.read_csv(os.path.join(DATA_PATH, POI_FILENAME))\n",
    "site_df = pd.read_csv(os.path.join(DATA_PATH, SITE_FILENAME))\n",
    "salary_df = pd.read_csv(os.path.join(DATA_PATH, SALARY_FILENAME))\n",
    "georef_df = pd.read_csv(os.path.join(DATA_PATH, GEOREF_FILENAME))\n",
    "stock_df = pd.read_csv(os.path.join(DATA_PATH, STOCK_FILENAME))\n",
    "sales_df = pd.read_csv(os.path.join(DATA_PATH, SALES_FILENAME))\n",
    "population_df = pd.read_csv(os.path.join(DATA_PATH, POPULATION_FILENAME))\n",
    "poverty_df = pd.read_csv(os.path.join(DATA_PATH, POVERTY_FILENAME))\n",
    "real_estate_df = pd.read_csv(os.path.join(DATA_PATH, REAL_ESTATE_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26216 entries, 0 to 26215\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   poi                26216 non-null  object \n",
      " 1   latitude           26216 non-null  float64\n",
      " 2   longitude          26216 non-null  float64\n",
      " 3   municipality_code  26216 non-null  object \n",
      " 4   importance         26216 non-null  float64\n",
      " 5   name_reprocessed   26216 non-null  object \n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 1.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31034 entries, 0 to 31033\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   poi                      31034 non-null  object \n",
      " 1   name                     31034 non-null  object \n",
      " 2   latitude                 31034 non-null  float64\n",
      " 3   longitude                31034 non-null  float64\n",
      " 4   municipality_code        31034 non-null  object \n",
      " 5   importance               31034 non-null  float64\n",
      " 6   name_reprocessed         31034 non-null  object \n",
      " 7   data_inside_parenthesis  21135 non-null  object \n",
      " 8   Category                 31034 non-null  object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 2.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26675 entries, 0 to 26674\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   municipality_code  26675 non-null  object \n",
      " 1   avg_net_salary     26675 non-null  float64\n",
      " 2   year               26675 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 625.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34997 entries, 0 to 34996\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   municipality_code     34997 non-null  object \n",
      " 1   city_name             34997 non-null  object \n",
      " 2   city_name_normalized  34997 non-null  object \n",
      " 3   municipality_type     34997 non-null  object \n",
      " 4   latitude              34997 non-null  float64\n",
      " 5   longitude             34997 non-null  float64\n",
      " 6   department_code       34997 non-null  object \n",
      " 7   epci_code             34945 non-null  float64\n",
      " 8   department_name       34997 non-null  object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 2.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 279584 entries, 0 to 279583\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   municipality_code     279584 non-null  object \n",
      " 1   year                  279584 non-null  int64  \n",
      " 2   nb_principal_home     279584 non-null  int64  \n",
      " 3   nb_second_home        279584 non-null  int64  \n",
      " 4   nb_vacants_housing    279584 non-null  int64  \n",
      " 5   nb_tot_housing        279584 non-null  int64  \n",
      " 6   secondary_home_rate   279584 non-null  float64\n",
      " 7   principal_home_rate   279584 non-null  float64\n",
      " 8   vacants_housing_rate  279584 non-null  float64\n",
      "dtypes: float64(3), int64(5), object(1)\n",
      "memory usage: 19.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3448398 entries, 0 to 3448397\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   sales_date                 object \n",
      " 1   sales_amount               float64\n",
      " 2   street_number              float64\n",
      " 3   street_code                object \n",
      " 4   street_name                object \n",
      " 5   nom_commune                object \n",
      " 6   municipality_code          object \n",
      " 7   premise_type               object \n",
      " 8   surface                    float64\n",
      " 9   number_of_principal_rooms  int64  \n",
      " 10  sales_price_m2             float64\n",
      " 11  latitude                   float64\n",
      " 12  longitude                  float64\n",
      "dtypes: float64(6), int64(1), object(6)\n",
      "memory usage: 342.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 689495 entries, 0 to 689494\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   municipality_code  689495 non-null  object \n",
      " 1   year               689495 non-null  int64  \n",
      " 2   population         689495 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 15.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 689495 entries, 0 to 689494\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   municipality_code  689495 non-null  object \n",
      " 1   year               689495 non-null  int64  \n",
      " 2   population         689495 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 15.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34441 entries, 0 to 34440\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   municipality_code       34441 non-null  object \n",
      " 1   intensite_tension_immo  34441 non-null  int64  \n",
      " 2   rental_max_apartment    34441 non-null  float64\n",
      " 3   rental_min_apartment    34441 non-null  float64\n",
      " 4   rental_med_all          34441 non-null  float64\n",
      " 5   rental_max_all          34441 non-null  float64\n",
      " 6   rental_min_all          34441 non-null  float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# DF CLEANED CHECK\n",
    "poi_df.info()\n",
    "site_df.info()\n",
    "salary_df.info()\n",
    "georef_df.info() \n",
    "stock_df.info() \n",
    "sales_df.info()\n",
    "population_df.info() \n",
    "poverty_df.info()\n",
    "real_estate_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ-ON4l9sVwu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ-ON4l9sVwu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DF_SALES CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FclUrSzCGdSX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3448398, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SALES_DF: Suppression des doublons > nous passons de 4,3M de lignes à 3,821M\n",
    "sales_df = sales_df.drop_duplicates()\n",
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SALES_DF: Check si les doublons on été enlevés : OK\n",
    "sales_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALES_DF: Suppression des prix au m2 supérieur à 30K€ et inférieur à 1K€ > nous passons à 3,3399M de lignes\n",
    "sales_df = sales_df[(sales_df['sales_price_m2'] <= 30000) & (sales_df['sales_price_m2'] >= 1000)]\n",
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALES_DF:\n",
    "s2 = (sales_df['sales_amount']\n",
    "             .value_counts()\n",
    "             .loc[sales_df['sales_amount'].value_counts() > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALES_DF:\n",
    "sales_df = sales_df[sales_df['sales_amount'] > 1] # on enlève les 166 fois ou sales_amount = 1€\n",
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3448398 entries, 0 to 3448397\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Dtype         \n",
      "---  ------                     -----         \n",
      " 0   sales_date                 datetime64[ns]\n",
      " 1   sales_amount               float64       \n",
      " 2   street_number              float64       \n",
      " 3   street_code                object        \n",
      " 4   street_name                object        \n",
      " 5   nom_commune                object        \n",
      " 6   municipality_code          object        \n",
      " 7   premise_type               object        \n",
      " 8   surface                    float64       \n",
      " 9   number_of_principal_rooms  int64         \n",
      " 10  sales_price_m2             float64       \n",
      " 11  latitude                   float64       \n",
      " 12  longitude                  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(5)\n",
      "memory usage: 342.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# SALES_DF: changement du type sales_date en datetime\n",
    "sales_df['sales_date'] = pd.to_datetime(sales_df['sales_date'])\n",
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DF_SALARY CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_SALARY: ROUND avg_net_salary\n",
    "salary_df['avg_net_salary'] = salary_df['avg_net_salary'].round()\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DF_REAL_ESTATE CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_REAL_ESTATE: suppression des nulls\n",
    "real_estate_df = real_estate_df.dropna(axis=1)\n",
    "real_estate_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DF_SITE CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITE_DF: tri avec les données entre parenthèses de la colonne \"name\" inclues\n",
    "\n",
    "import re\n",
    "\n",
    "site_df['data_inside_parenthesis'] = site_df['name'].apply(lambda x: re.search(r'\\((.*?)\\)', x).group(1) if re.search(r'\\((.*?)\\)', x) else '')\n",
    "site_df\n",
    "\n",
    "#suppression de la colonne \"name\" dans un second temps\n",
    "\n",
    "site_df.drop(columns=[\"name\"])\n",
    "\n",
    "#check pour savoir les informations présentes dans la colonne \"poi\", et si elles correspondent aux valeurs présentes dans la colonne \"type\"\n",
    "print (site_df[\"poi\"].value_counts())\n",
    "print (site_df[\"data_inside_parenthesis\"].value_counts().head(50))\n",
    "\n",
    "#faire un mapping des colonnes poi, qui sont en fait plus pertinentes que celles de la colonne \"type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITE_DF: création d'un dictionnaire intégrant toutes les différentes valeurs inclues dans la colonne \"poi\"\n",
    "s = site_df[\"poi\"].value_counts()[site_df[\"poi\"]]\n",
    "{k: \"toto\" for k in s.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITE_DF: création d'un dictionnaire avec les catégories associées aux valeurs de la colonne POI\n",
    "\n",
    "category_dict = {'1': 'Patrimoine',\n",
    " '2': 'Patrimoine',\n",
    " 'zoo': 'Entertainment',\n",
    " 'dune': 'Nature',\n",
    " 'park': 'Nature',\n",
    " 'rock': 'Nature',\n",
    " 'sand': 'Nature',\n",
    " 'beach': 'Nature',\n",
    " 'cliff': 'Nature',\n",
    " 'islet': 'Nature',\n",
    " 'ridge': 'Nature',\n",
    " 'water': 'Nature',\n",
    " 'wreck': 'Patrimoine',\n",
    " 'casino': 'Entertainment',\n",
    " 'castle': 'Patrimoine',\n",
    " 'cinema': 'Culture',\n",
    " 'forest': 'Nature',\n",
    " 'geyser': 'Nature',\n",
    " 'marina': 'Nature',\n",
    " 'meadow': 'Nature',\n",
    " 'museum': 'Culture',\n",
    " 'valley': 'Nature',\n",
    " 'theatre': 'Culture',\n",
    " 'volcano': 'Nature',\n",
    " 'wetland': 'Nature',\n",
    " 'heritage': 'Patrimoine',\n",
    " 'monument': 'Patrimoine',\n",
    " 'vineyard': 'Nature',\n",
    " 'viewpoint': 'Nature',\n",
    " 'waterfall': 'Nature',\n",
    " 'allotments': 'Patrimoine',\n",
    " 'attraction': 'Entertainment',\n",
    " 'theme_park': 'Entertainment',\n",
    " 'water_park': 'Entertainment',\n",
    " 'golf_course': 'Entertainment',\n",
    " 'cave_entrance': 'Culture',\n",
    " 'national_park': 'Nature',\n",
    " 'protected_area': 'Nature'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITE_DF: création de la colonne \"catégorie\"\n",
    "site_df[\"Category\"] = site_df[\"poi\"].map(category_dict)\n",
    "site_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df.info()\n",
    "site_df.info()\n",
    "salary_df.info()\n",
    "georef_df.info() \n",
    "stock_df.info() \n",
    "sales_df.info()\n",
    "population_df.info() \n",
    "poverty_df.info()\n",
    "real_estate_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_df.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "georef_df.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0j9hJqlFaEc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 🧪 **DATA TRANSFORMATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S"
   },
   "source": [
    "### KPIS AGGREGATION BY DEPARTMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 1. POPULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Salaire moyen par département\n",
    "# Joindre les informations de géolocalisation pour obtenir les départements\n",
    "salary_dep_df = salary_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer le salaire moyen par département\n",
    "avg_salary_per_department = salary_dep_df.groupby(['department_code', 'department_name'])['avg_net_salary'].mean().reset_index().round()\n",
    "avg_salary_per_department.rename(columns={'avg_net_salary': 'avg_salary'}, inplace=True)\n",
    "avg_salary_per_department.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Évolution de la population par département\n",
    "# Joindre les informations de géolocalisation pour obtenir les départements\n",
    "population_dep_df = population_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer l'évolution de la population par département (différence entre les années)\n",
    "pop_evolution = population_dep_df.groupby(['department_code', 'department_name', 'year'])['population'].sum().unstack().reset_index()\n",
    "pop_evolution['evolution'] = (pop_evolution[pop_evolution.columns[-1]] - pop_evolution[pop_evolution.columns[-2]]) / pop_evolution[pop_evolution.columns[-2]] * 100\n",
    "pop_evolution = pop_evolution[['department_code', 'department_name', 'evolution']]\n",
    "\n",
    "pop_evolution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Taux de pauvreté par département\n",
    "# Joindre les données de population\n",
    "poverty_df = poverty_df.merge(population_df[['municipality_code', 'population']], on='municipality_code', suffixes=('_poverty', '_population'))\n",
    "\n",
    "# Merge avec georef pour avoir le department_name\n",
    "poverty_df = poverty_df.merge(georef_df[['municipality_code', 'department_name']], on='municipality_code', how='left')\n",
    "\n",
    "# Groupe par department_name pour calculer le taux de pauvreté par département\n",
    "poverty_by_department = poverty_df.groupby('department_name').agg({\n",
    "    'population_poverty': 'sum',\n",
    "    'population_population': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculer le poverty_rate pour chaque département\n",
    "poverty_by_department['poverty_rate'] = (poverty_by_department['population_poverty'] / poverty_by_department['population']) * 100\n",
    "\n",
    "# Afficher le résultat\n",
    "poverty_by_department.head()\n",
    "\n",
    "# calcul = poverty_rate = poverty_population / total_population * 100\n",
    "# il faut ensuite le DF qui a poverty_rate à georef pour récupérer le department_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2. TOURISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Nombre de sites touristiques par département\n",
    "# Joindre les informations de géolocalisation pour obtenir les départements\n",
    "site_dep_df = site_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer le nombre de sites touristiques par département\n",
    "num_sites_per_department = site_dep_df.groupby(['department_code', 'department_name'])['poi'].count().reset_index()\n",
    "num_sites_per_department.rename(columns={'poi': 'nb_sites'}, inplace=True)\n",
    "num_sites_per_department.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Importance moyenne des sites par département\n",
    "# Calculer l'importance moyenne des sites touristiques par département\n",
    "avg_site_importance_per_department = site_dep_df.groupby(['department_code', 'department_name'])['importance'].mean().reset_index()\n",
    "avg_site_importance_per_department.rename(columns={'importance': 'avg_site_importance'}, inplace=True)\n",
    "avg_site_importance_per_department.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Stock de logement par département\n",
    "# Joindre les informations de géolocalisation pour obtenir les départements\n",
    "stock_dep_df = stock_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer le stock de logement par département (nombre total de logements)\n",
    "total_stock_per_department = stock_dep_df.groupby(['department_code', 'department_name'])['nb_tot_housing'].sum().reset_index()\n",
    "total_stock_per_department.rename(columns={'nb_tot_housing': 'total_stock'}, inplace=True)\n",
    "total_stock_per_department.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S"
   },
   "source": [
    "##### 3. REAL ESTATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Rentabilité locative au m² par département\n",
    "# Joindre les informations de géolocalisation pour obtenir les départements\n",
    "real_estate_dep_df = real_estate_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer la rentabilité locative moyenne au m² par département\n",
    "real_estate_dep_df['avg_rental_yield'] = (real_estate_dep_df['rental_max_all'] + real_estate_dep_df['rental_min_all']) / 2\n",
    "rental_yield_per_department = real_estate_dep_df.groupby(['department_code', 'department_name'])['avg_rental_yield'].mean().reset_index()\n",
    "rental_yield_per_department.rename(columns={'avg_rental_yield': 'avg_rental_yield'}, inplace=True)\n",
    "rental_yield_per_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Tension immobilière par département\n",
    "# Calculer la tension immobilière par département\n",
    "housing_tension_per_department = real_estate_dep_df.groupby(['department_code', 'department_name'])['intensite_tension_immo'].mean().reset_index()\n",
    "housing_tension_per_department.rename(columns={'intensite_tension_immo': 'avg_housing_tension'}, inplace=True)\n",
    "housing_tension_per_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Part de maisons secondaires par département\n",
    "# Calculer la part de maisons secondaires par département\n",
    "secondary_home_rate_per_department = stock_dep_df.groupby(['department_code', 'department_name'])['secondary_home_rate'].mean().reset_index()\n",
    "secondary_home_rate_per_department.rename(columns={'secondary_home_rate': 'avg_secondary_home_rate'}, inplace=True)\n",
    "secondary_home_rate_per_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Évolution du prix au m² par département\n",
    "# Joindre les informations de géolocalisation pour obtenir les départements\n",
    "sales_dep_df = sales_df.merge(georef_df[['municipality_code', 'department_code', 'department_name']], on='municipality_code')\n",
    "\n",
    "# Calculer l'évolution du prix au m² par département\n",
    "price_evolution = sales_dep_df.groupby(['department_code', 'department_name', 'sales_date'])['sales_price_m2'].mean().unstack().reset_index()\n",
    "price_evolution['price_evolution'] = (price_evolution[price_evolution.columns[-1]] - price_evolution[price_evolution.columns[-2]]) / price_evolution[price_evolution.columns[-2]] * 100\n",
    "price_evolution = price_evolution[['department_code', 'department_name', 'price_evolution']]\n",
    "price_evolution.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le prix moyen au m² des ventes immobilières par département\n",
    "avg_price_per_m2_per_department = sales_dep_df.groupby(['department_code', 'department_name'])['sales_price_m2'].mean().reset_index()\n",
    "avg_price_per_m2_per_department.rename(columns={'sales_price_m2': 'avg_sales_price_m2'}, inplace=True)\n",
    "avg_price_per_m2_per_department.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population\n",
    "1.1 Salaire moyen par département\n",
    "1.2 Évolution de la population par département\n",
    "1.3 Taux de pauvreté par département\n",
    "\n",
    "Tourisme\n",
    "2.1 Nombre de sites touristiques par département\n",
    "2.2 Importance moyenne des sites par département\n",
    "2.3 Stock de logement par département\n",
    "\n",
    "Immobilier\n",
    "3.1 Rentabilité locative au m² par département\n",
    "3.2 Tension immobilière par département\n",
    "3.3 Part de maisons secondaires par département\n",
    "3.4 Évolution du prix au m² par département\n",
    "3.5 Prix moyen au m² des ventes immobilières par département\n",
    "creer moi un système de scoring (avec pondération) pour avoir :\n",
    "\n",
    "un score Population\n",
    "un score Tourisme\n",
    "un score Immobilier\n",
    "puis un Score Global grâce aux 3 précédents scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que vous avez déjà calculé les données nécessaires pour les scores Population, Tourisme et Immobilier\n",
    "\n",
    "# 1. Définition des poids pour chaque sous-score dans chaque catégorie\n",
    "weights_population = {\n",
    "    'average_salary': 0.4,\n",
    "    'population_growth': 0.3,\n",
    "    'poverty_rate': 0.3\n",
    "}\n",
    "\n",
    "weights_tourism = {\n",
    "    'num_tourism_sites': 0.4,\n",
    "    'average_importance': 0.3,\n",
    "    'stock_housing': 0.3\n",
    "}\n",
    "\n",
    "weights_real_estate = {\n",
    "    'rental_yield_per_m2': 0.2,\n",
    "    'real_estate_tension': 0.2,\n",
    "    'secondary_home_rate': 0.1,\n",
    "    'price_growth': 0.2,\n",
    "    'average_price_per_m2': 0.3\n",
    "}\n",
    "\n",
    "# 2. Calcul des scores pour chaque catégorie\n",
    "\n",
    "# POPULATION\n",
    "# Supposons que vous avez déjà les dataframes suivants : average_salary_by_department, population_evolution_by_department, average_poverty_rate_by_department\n",
    "\n",
    "population_scores = (\n",
    "    avg_salary_per_department['avg_salary'] * weights_population['average_salary'] +\n",
    "    pop_evolution['evolution'] * weights_population['population_growth'] +\n",
    "    (100 - average_poverty_rate_by_department['poverty_rate']) * weights_population['poverty_rate']\n",
    ")\n",
    "\n",
    "# TOURISM\n",
    "# Supposons que vous avez déjà les dataframes suivants : tourism_sites_by_department, average_importance_by_department, stock_housing_by_department\n",
    "\n",
    "tourism_scores = (\n",
    "    tourism_sites_by_department['num_tourism_sites'] * weights_tourism['num_tourism_sites'] +\n",
    "    average_importance_by_department['importance'] * weights_tourism['average_importance'] +\n",
    "    stock_housing_by_department['stock_housing'] * weights_tourism['stock_housing']\n",
    ")\n",
    "\n",
    "# REAL ESTATE\n",
    "# Supposons que vous avez déjà les dataframes suivants : rental_yield_per_m2_by_department, real_estate_tension_by_department, second_home_rate_by_department, price_growth_by_department, average_price_per_m2_by_department\n",
    "\n",
    "real_estate_scores = (\n",
    "    rental_yield_per_m2_by_department['rental_yield_per_m2'] * weights_real_estate['rental_yield_per_m2'] +\n",
    "    (100 - real_estate_tension_by_department['intensite_tension_immo']) * weights_real_estate['real_estate_tension'] +\n",
    "    (100 - second_home_rate_by_department['secondary_home_rate']) * weights_real_estate['secondary_home_rate'] +\n",
    "    price_growth_by_department['price_growth'] * weights_real_estate['price_growth'] +\n",
    "    average_price_per_m2_by_department['average_price_per_m2'] * weights_real_estate['average_price_per_m2']\n",
    ")\n",
    "\n",
    "# 3. Calcul du score global\n",
    "# Supposons que les scores sont déjà calculés pour chaque catégorie\n",
    "\n",
    "global_score = (\n",
    "    population_scores +\n",
    "    tourism_scores +\n",
    "    real_estate_scores\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser les résultats\n",
    "print(\"Scores Population :\\n\", population_scores.head())\n",
    "print(\"\\nScores Tourisme :\\n\", tourism_scores.head())\n",
    "print(\"\\nScores Immobilier :\\n\", real_estate_scores.head())\n",
    "print(\"\\nScore Global :\\n\", global_score.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPULATION SCORE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Supposons que vous avez déjà calculé les sous-scores pour la catégorie Population : average_salary_by_department, population_evolution_by_department, average_poverty_rate_by_department\n",
    "\n",
    "# Initialisation du MinMaxScaler\n",
    "scaler_population = MinMaxScaler()\n",
    "\n",
    "# Normalisation des données\n",
    "population_scores_scaled = scaler_population.fit_transform(\n",
    "    population_scores[['avg_net_salary', 'population_growth', 'poverty_rate']]\n",
    ")\n",
    "\n",
    "# Calcul des scores normalisés\n",
    "population_scores_normalized = (\n",
    "    population_scores_scaled[:, 0] * weights_population['average_salary'] +\n",
    "    population_scores_scaled[:, 1] * weights_population['population_growth'] +\n",
    "    population_scores_scaled[:, 2] * weights_population['poverty_rate']\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser les résultats des scores normalisés\n",
    "print(\"Scores Population normalisés :\\n\", population_scores_normalized.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOURISM SCORE\n",
    "# Supposons que vous avez déjà calculé les sous-scores pour la catégorie Tourisme : tourism_sites_by_department, average_importance_by_department, stock_housing_by_department\n",
    "\n",
    "# Initialisation du MinMaxScaler\n",
    "scaler_tourism = MinMaxScaler()\n",
    "\n",
    "# Normalisation des données\n",
    "tourism_scores_scaled = scaler_tourism.fit_transform(\n",
    "    tourism_scores[['num_tourism_sites', 'average_importance', 'stock_housing']]\n",
    ")\n",
    "\n",
    "# Calcul des scores normalisés\n",
    "tourism_scores_normalized = (\n",
    "    tourism_scores_scaled[:, 0] * weights_tourism['num_tourism_sites'] +\n",
    "    tourism_scores_scaled[:, 1] * weights_tourism['average_importance'] +\n",
    "    tourism_scores_scaled[:, 2] * weights_tourism['stock_housing']\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser les résultats des scores normalisés\n",
    "print(\"Scores Tourisme normalisés :\\n\", tourism_scores_normalized.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 REAL ESTATE SCORE\n",
    "# Supposons que vous avez déjà calculé les sous-scores pour la catégorie Immobilier : rental_yield_per_m2_by_department, real_estate_tension_by_department, second_home_rate_by_department, price_growth_by_department, average_price_per_m2_by_department\n",
    "\n",
    "# Initialisation du MinMaxScaler\n",
    "scaler_real_estate = MinMaxScaler()\n",
    "\n",
    "# Normalisation des données\n",
    "real_estate_scores_scaled = scaler_real_estate.fit_transform(\n",
    "    real_estate_scores[['rental_yield_per_m2', 'real_estate_tension', 'secondary_home_rate', 'price_growth', 'average_price_per_m2']]\n",
    ")\n",
    "\n",
    "# Calcul des scores normalisés\n",
    "real_estate_scores_normalized = (\n",
    "    real_estate_scores_scaled[:, 0] * weights_real_estate['rental_yield_per_m2'] +\n",
    "    real_estate_scores_scaled[:, 1] * weights_real_estate['real_estate_tension'] +\n",
    "    real_estate_scores_scaled[:, 2] * weights_real_estate['secondary_home_rate'] +\n",
    "    real_estate_scores_scaled[:, 3] * weights_real_estate['price_growth'] +\n",
    "    real_estate_scores_scaled[:, 4] * weights_real_estate['average_price_per_m2']\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser les résultats des scores normalisés\n",
    "print(\"Scores Immobilier normalisés :\\n\", real_estate_scores_normalized.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 GLOBAL SCORE\n",
    "# Supposons que vous avez déjà les scores normalisés pour chaque catégorie\n",
    "# population_scores_normalized, tourism_scores_normalized, real_estate_scores_normalized\n",
    "\n",
    "# Définition des poids pour chaque catégorie\n",
    "weights = {\n",
    "    'population': 0.4,\n",
    "    'tourism': 0.3,\n",
    "    'real_estate': 0.3\n",
    "}\n",
    "\n",
    "# Calcul du score global pondéré\n",
    "global_score = (\n",
    "    population_scores_normalized * weights['population'] +\n",
    "    tourism_scores_normalized * weights['tourism'] +\n",
    "    real_estate_scores_normalized * weights['real_estate']\n",
    ")\n",
    "\n",
    "# Afficher ou utiliser le score global\n",
    "print(\"Score Global :\\n\", global_score.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYnKDVU0sb0S",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 🚀 ENRICHED EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MtiYSUHHSCws",
    "qzPmsWEUq5zk",
    "Qhf-qyfBrBrU",
    "WUbRvCbWrC-g",
    "IaW8clyJrE7k",
    "gHemM-SqrGyN",
    "wDh1nf-1rIgb",
    "DEROdiJirK6M",
    "-pWIMamvrMgo",
    "i0j9hJqlFaEc",
    "FZ-ON4l9sVwu",
    "XYnKDVU0sb0S",
    "sNX4qmi1Gdyx"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
